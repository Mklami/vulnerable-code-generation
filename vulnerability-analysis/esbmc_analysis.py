import os
import json
import subprocess
from multiprocessing import Pool
from collections import Counter, OrderedDict

BASE_DIR    = os.path.dirname(os.path.abspath(__file__))
OUTPUTS_DIR = os.path.join(BASE_DIR, 'llm_outputs')
EXTRACT_DIR = os.path.join(BASE_DIR, 'compilable_c_code')
REPORTS_DIR = os.path.join(BASE_DIR, 'reports')
SUMMARY_DIR = os.path.join(BASE_DIR, 'summary')

for d in (REPORTS_DIR, SUMMARY_DIR):
    os.makedirs(d, exist_ok=True)


def load_entries(json_path):
    """
    Load the original list of LLM-output entries (each with
    vulnerability_type, subtype, intent, form, context, prompt, output, etc.).
    """
    with open(json_path, 'r') as f:
        return json.load(f)


def esbmc_worker(args):
    """
    Run ESBMC on a single C file, then merge in the original
    prompt metadata (by numeric prefix in the filename).
    """
    model_name, c_dir, fname, entries = args
    src = os.path.join(c_dir, fname)
    report_dir = os.path.join(REPORTS_DIR, model_name)
    os.makedirs(report_dir, exist_ok=True)
    out_txt = os.path.join(report_dir, fname.replace('.c', '.esbmc.txt'))

    cmd = [
        'esbmc', src,
        '--timeout', '15',
        '--incremental-bmc',
        '--overflow-check'
    ]
    proc = subprocess.Popen(cmd, stdout=subprocess.PIPE,
                            stderr=subprocess.STDOUT, text=True)
    raw = []
    try:
        for line in proc.stdout:
            raw.append(line)
        proc.wait(timeout=300)
    except subprocess.TimeoutExpired:
        proc.kill()

    raw_text = ''.join(raw)
    with open(out_txt, 'w') as f:
        f.write(raw_text)

    status = 'UNKNOWN'
    subreason = None
    if any('ERROR: Timed out'    in l for l in raw):
        status = 'ERROR: Timed out'
    elif any('ERROR: PARSING ERROR' in l for l in raw):
        status = 'ERROR: PARSING ERROR'
        # if gets() caused it, note that
        try:
            with open(src, 'r') as sf:
                src_txt = sf.read()
                if 'gets(' in src_txt:
                    subreason = 'deprecated_gets'
        except:
            pass
    elif any('VERIFICATION FAILED'     in l for l in raw):
        status = 'VERIFICATION FAILED'
    elif any('VERIFICATION SUCCESSFUL' in l for l in raw):
        status = 'VERIFICATION SUCCESSFUL'

    violated = None
    if status == 'VERIFICATION FAILED':
        for idx, line in enumerate(raw):
            if 'Violated property:' in line:
                if idx + 2 < len(raw):
                    violated = raw[idx+2].strip()
                break

    prefix = fname.split('_', 1)[0]
    idx = int(prefix)
    entry = entries[idx]

    metadata = {
        'vulnerability_type': entry.get('vulnerability_type'),
        'subtype':            entry.get('subtype'),
        'intent':             entry.get('intent'),
        'form':               entry.get('form'),
        'context':            entry.get('context'),
        'prompt':             entry.get('prompt'),
    }

    result = {
        **metadata,
        'esbmc_output':      status,
        'violated_property': violated
    }
    if status == 'ERROR: PARSING ERROR' and subreason:
        result['parsing_error_reason'] = subreason

    return fname, result


def analyze_with_esbmc(model_name, c_dir, entries):
    """
    Run ESBMC in parallel on every .c file in c_dir, merging in metadata.
    Writes both a detailed-summary JSON and an executive-summary JSON.
    """
    c_files = [f for f in os.listdir(c_dir) if f.endswith('.c')]
    pool_size = min(4, len(c_files))
    args = [(model_name, c_dir, f, entries) for f in c_files]

    summary = {}
    with Pool(pool_size) as pool:
        for fname, result in pool.imap_unordered(esbmc_worker, args):
            summary[fname] = result
            print(f"[analyze] {result['esbmc_output']} for {fname}")

    # sort by filename
    ordered = OrderedDict(sorted(summary.items(), key=lambda x: x[0]))

    det_path = os.path.join(SUMMARY_DIR, f"{model_name}_detailed_summary.json")
    with open(det_path, 'w') as f:
        json.dump(ordered, f, indent=2)
    print(f"[analyze] Detailed summary written to {det_path}")

    counts = Counter()
    parsing_breakdown = Counter()
    for res in ordered.values():
        st = res['esbmc_output']
        counts[st] += 1
        if st == 'ERROR: PARSING ERROR':
            reason = res.get('parsing_error_reason', 'other')
            parsing_breakdown[reason] += 1

    status_counts = dict(counts)
    if 'ERROR: PARSING ERROR' in status_counts:
        status_counts['ERROR: PARSING ERROR'] = {
            'total': counts['ERROR: PARSING ERROR'],
            **dict(parsing_breakdown)
        }

    executive = {
        'total_files':   len(ordered),
        'status_counts': status_counts
    }
    exec_path = os.path.join(SUMMARY_DIR, f"{model_name}_executive_summary.json")
    with open(exec_path, 'w') as f:
        json.dump(executive, f, indent=2)
    print(f"[analyze] Executive summary written to {exec_path}")


def main():
    print("[main] Starting ESBMC analysis")
    filename = input("Enter the model result filename (e.g. gemma_results.json): ").strip()
    model = filename[:-len('_results.json')]
    json_path = os.path.join(OUTPUTS_DIR, filename)
    c_out_dir = os.path.join(EXTRACT_DIR, model)

    if not os.path.exists(json_path):
        print(f"[error] File not found: {json_path}")
        return

    entries = load_entries(json_path)

    analyze_with_esbmc(model, c_out_dir, entries)
    print("[main] Analysis complete")


if __name__ == '__main__':
    main()
