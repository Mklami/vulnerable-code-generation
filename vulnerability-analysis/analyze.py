import os
import json
import subprocess
import re
from multiprocessing import Pool, cpu_count

BASE_DIR    = os.path.dirname(os.path.abspath(__file__))
OUTPUTS_DIR = os.path.join(BASE_DIR, 'llm_outputs')
EXTRACT_DIR = os.path.join(BASE_DIR, 'compilable_c_code')
REPORTS_DIR = os.path.join(BASE_DIR, 'reports')
SUMMARY_DIR = os.path.join(BASE_DIR, 'summary')

# Common headers to inject if missing
COMMON_HEADERS = [
    '<stdio.h>',
    '<stdlib.h>',
    '<string.h>',
    '<stdint.h>',
    '<stddef.h>',
    '<stdbool.h>'
]

for d in (EXTRACT_DIR, REPORTS_DIR, SUMMARY_DIR):
    os.makedirs(d, exist_ok=True)


def extract_c_files(json_path, out_dir):
    """
    Extract C code blocks from <model>_results.json into .c files,
    prepend missing common headers, and return a mapping of filenames to the original prompts.
    """
    print(f"[extract] Loading prompts from {json_path}")
    os.makedirs(out_dir, exist_ok=True)
    with open(json_path, 'r') as f:
        entries = json.load(f)

    fence_re = re.compile(r'<code>\s*(.*?)</code>', re.DOTALL)
    prompts_map = {}
    skipped = 0

    for i, entry in enumerate(entries):
        output = entry.get('output', '')
        m = fence_re.search(output)
        if not m:
            print(f"[extract] No code fence in entry {i}; skipping")
            skipped += 1
            continue
        code_body = m.group(1).strip()

        # Determine which common headers are missing
        missing = []
        for hdr in COMMON_HEADERS:
            include_stmt = f'#include {hdr}'
            if include_stmt not in code_body:
                missing.append(include_stmt)

        # Prepend missing headers and a blank line
        if missing:
            header_block = "\n".join(missing) + "\n\n"
            full_code = header_block + code_body + "\n"
        else:
            full_code = code_body + "\n"

        fname = f"{i:03d}.c"
        path = os.path.join(out_dir, fname)
        with open(path, 'w') as cf:
            cf.write(full_code)
        print(f"[extract] Wrote {path} (injected {len(missing)} headers)")

        # store the original prompt for this snippet
        prompts_map[fname] = entry.get('prompt', entry.get('input', ''))

    total = len(entries) - skipped
    print(f"[extract] Extracted {total}/{len(entries)} .c files to {out_dir}")
    return prompts_map


def esbmc_worker(args):
    """Worker to run ESBMC on a single file."""
    model_name, c_dir, fname, prompts_map = args
    src = os.path.join(c_dir, fname)
    report_dir = os.path.join(REPORTS_DIR, model_name)
    os.makedirs(report_dir, exist_ok=True)
    out_txt = os.path.join(report_dir, fname.replace('.c', '.esbmc.txt'))

    cmd = ['esbmc', src, '--unwind', '0', '--timeout', '30', '--k-induction', '--incremental-bmc']
    proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)
    raw = []
    try:
        for line in proc.stdout:
            raw.append(line)
        proc.wait(timeout=300)
    except subprocess.TimeoutExpired:
        proc.kill()

    raw_text = '\n'.join(raw)
    with open(out_txt, 'w') as f:
        f.write(raw_text)

    # parse status
    status = 'UNKNOWN'
    if any('ERROR: Timed out' in l for l in raw):
        status = 'ERROR: Timed out'
    elif any('ERROR: PARSING ERROR' in l for l in raw):
        status = 'ERROR: PARSING ERROR'
    elif any('VERIFICATION FAILED' in l for l in raw):
        status = 'VERIFICATION FAILED'
    elif any('VERIFICATION SUCCESSFUL' in l for l in raw):
        status = 'VERIFICATION SUCCESSFUL'

    violated = None
    if status == 'VERIFICATION FAILED':
        for i, line in enumerate(raw):
            if 'Violated property:' in line:
                if i+2 < len(raw):
                    violated = raw[i+2].strip()
                break

    return fname, {
        'prompt': prompts_map.get(fname, ''),
        'esbmc_output': status,
        'violated_property': violated
    }


def analyze_with_esbmc(model_name, c_dir, prompts_map):
    """Parallel ESBMC analysis."""
    c_files = [f for f in os.listdir(c_dir) if f.endswith('.c')]
    pool_size = min(cpu_count(), len(c_files))
    args = [(model_name, c_dir, f, prompts_map) for f in c_files]

    summary = {}
    with Pool(pool_size) as pool:
        for fname, result in pool.imap_unordered(esbmc_worker, args):
            summary[fname] = result
            print(f"[analyze] {result['esbmc_output']} for {fname}")

    summary_path = os.path.join(SUMMARY_DIR, f"{model_name}_detailed_summary.json")
    with open(summary_path, 'w') as f:
        json.dump(summary, f, indent=2)
    print(f"[analyze] Detailed summary at {summary_path}")


def compile_c_files(c_dir):
    """
    Try to compile each .c file in c_dir with gcc -std=gnu11 -Wall.
    Returns a dict mapping filename -> (success: bool, stderr: str).
    Afterwards, deletes every non-.c file in c_dir.
    """
    compile_results = {}

    for fname in sorted(os.listdir(c_dir)):
        if not fname.endswith('.c'):
            continue

        src_path = os.path.join(c_dir, fname)
        bin_path = os.path.join(c_dir, fname[:-2] + '.out')
        # removed -Werror, added -std=gnu11
        cmd = ['gcc', '-std=gnu11', '-Wall', src_path, '-o', bin_path]

        try:
            subprocess.run(
                cmd,
                check=True,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True
            )
            compile_results[fname] = (True, "")
        except subprocess.CalledProcessError as e:
            # capture *all* stderr so you can see the real warnings
            compile_results[fname] = (False, e.stderr)

    # Clean up: remove everything except .c
    for other in os.listdir(c_dir):
        if not other.endswith('.c'):
            os.remove(os.path.join(c_dir, other))

    return compile_results


def main():
    print("[main] Starting analysis pipeline")
    result_files = [fn for fn in os.listdir(OUTPUTS_DIR) if fn.endswith('_results.json')]
    for fn in result_files:
        model = fn[:-len('_results.json')]
        print(f"[main] === Model: {model} ===")
        json_path = os.path.join(OUTPUTS_DIR, fn)
        c_out_dir = os.path.join(EXTRACT_DIR, model)

        # extract code and get prompts map
        prompts_map = extract_c_files(json_path, c_out_dir)

        # compile‚Äêcheck the .c files, clean up all other artifacts
        # print(f"[compile] Checking compilability in {c_out_dir}")
        # comp_results = compile_c_files(c_out_dir)
        # succ = sum(1 for ok, _ in comp_results.values() if ok)
        # fail = len(comp_results) - succ
        # print(f"[compile] {succ}/{len(comp_results)} files compiled successfully, {fail} failed")
        # if fail:
        #     print("[compile] Failures detail (full stderr):")
        #     for fname, (ok, err) in comp_results.items():
        #         if not ok:
        #             print(f"\n--- {fname} stderr ---")
        #             print(err.strip())

        # analyze and include detailed vulnerability and prompt info
        analyze_with_esbmc(model, c_out_dir, prompts_map)

    print("[main] All analyses complete")

if __name__ == '__main__':
    main()
